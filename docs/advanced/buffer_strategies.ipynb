{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Delay differential equations (DDEs) are computationally demanding because they require maintaining and accessing a history of past states. In brain network models, transmission delays arise from finite axonal conduction speeds, turning the system into a DDE where coupling terms depend on states at previous time points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install dependencies if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab - installing dependencies...\")\n",
    "    !pip install -q tvboptim\n",
    "    print(\"✓ Dependencies installed!\")\n",
    "except ImportError:\n",
    "    pass  # Not in Colab, assume dependencies are available"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core challenge is **history buffer management**: at each integration step, we must:\n",
    "\n",
    "1. Store the current state in a buffer\n",
    "2. Retrieve states from specific past times (per-connection delays)\n",
    "3. Update the buffer for the next step\n",
    "\n",
    "In JAX, how we implement this buffer management significantly impacts performance—and there is no universal best approach. The optimal strategy depends on:\n",
    "\n",
    "- Network size (number of nodes)\n",
    "- Time step size (determines buffer length)\n",
    "- Whether you need gradients (reverse-mode autodiff has different memory access patterns)\n",
    "- **Hardware**: CPU vs GPU have different memory bandwidth and access patterns\n",
    "\n",
    "::: {.callout-note}\n",
    "## Hardware Dependency\n",
    "The benchmarks in this document were run on **CPU**. Results can vary significantly on different hardware, especially when switching to **GPU**. GPUs typically have much higher memory bandwidth, which can change the relative performance of buffer strategies. We recommend re-running benchmarks on your target hardware with the desired model configuration.\n",
    ":::\n",
    "\n",
    "This document benchmarks three buffer strategies across different configurations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tvboptim.experimental.network_dynamics import Network, prepare\n",
    "from tvboptim.experimental.network_dynamics.dynamics.tvb import Generic2dOscillator\n",
    "from tvboptim.experimental.network_dynamics.coupling import DelayedLinearCoupling\n",
    "from tvboptim.experimental.network_dynamics.graph import DenseDelayGraph\n",
    "from tvboptim.experimental.network_dynamics.noise import AdditiveNoise\n",
    "from tvboptim.experimental.network_dynamics.solvers import Heun\n",
    "from tvboptim.utils import set_cache_path, cache\n",
    "\n",
    "# Set cache path for benchmark results\n",
    "set_cache_path(\"./buffer_benchmark\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer Strategies\n",
    "\n",
    "TVB-Optim implements three strategies for managing the history buffer in delay coupling:\n",
    "\n",
    "### Roll Strategy\n",
    "\n",
    "```python\n",
    "buffer = jnp.roll(buffer, shift=-1, axis=0)\n",
    "buffer = buffer.at[-1].set(new_state)\n",
    "```\n",
    "\n",
    "The **roll** strategy shifts all buffer entries by one position and writes the new state at the end. This is conceptually simple but involves copying the entire buffer at each step.\n",
    "\n",
    "### Circular Strategy\n",
    "\n",
    "```python\n",
    "write_idx = step % buffer_length\n",
    "buffer = buffer.at[write_idx].set(new_state)\n",
    "# Read indices computed with modular arithmetic\n",
    "```\n",
    "\n",
    "The **circular** strategy maintains a write pointer that wraps around. No data movement is required—only the pointer advances. Reading requires modular index computation.\n",
    "\n",
    "### Preallocated Strategy\n",
    "\n",
    "```python\n",
    "# Before simulation: allocate full trajectory\n",
    "trajectory = jnp.zeros((n_steps, n_states, n_nodes))\n",
    "\n",
    "# During simulation: write directly\n",
    "trajectory = trajectory.at[step].set(new_state)\n",
    "```\n",
    "\n",
    "The **preallocated** strategy allocates space for the entire trajectory upfront and writes sequentially. This avoids buffer management entirely but requires knowing the simulation length in advance and uses more memory.\n",
    "\n",
    "::: {.callout-note}\n",
    "The `buffer_strategy` parameter in `DelayedLinearCoupling` allows you to select the strategy:\n",
    "\n",
    "```python\n",
    "coupling = DelayedLinearCoupling(\n",
    "    incoming_states=\"V\",\n",
    "    G=1.0,\n",
    "    buffer_strategy=\"circular\"  # or \"roll\" (default), \"preallocated\"\n",
    ")\n",
    "```\n",
    ":::\n",
    "\n",
    "## Benchmark Configuration\n",
    "\n",
    "We benchmark all three strategies across:\n",
    "\n",
    "- **Network sizes**: 10, 20, 50, 100, 200 nodes\n",
    "- **Time steps (dt)**: 1.0, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01 ms\n",
    "\n",
    "Smaller dt values create larger history buffers (more past states to store for the same physical delay)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Benchmark configuration\n",
    "DT_VALUES = [1.0, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01]\n",
    "NETWORK_SIZES = [10, 20, 50, 100, 200]\n",
    "FIXED_TIMESTEPS = 5_000  # Number of simulation steps\n",
    "N_FORWARD_RUNS = 3       # Runs for forward timing\n",
    "N_GRADIENT_RUNS = 3      # Runs for gradient timing\n",
    "G = 0.001                # Coupling strength\n",
    "MAX_DELAY = 50           # Maximum delay in ms\n",
    "STRATEGIES = [\"roll\", \"circular\", \"preallocated\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def create_network(graph, G, buffer_strategy):\n",
    "    \"\"\"Create a network with the specified buffer strategy.\"\"\"\n",
    "    return Network(\n",
    "        dynamics=Generic2dOscillator(\n",
    "            a=-1.5,\n",
    "            tau=4.0,\n",
    "            b=-15.0,\n",
    "            c=0.0,\n",
    "            d=0.015,\n",
    "            e=3.0,\n",
    "            f=1.0,\n",
    "            g=0.0,\n",
    "            I=0.0,\n",
    "            INITIAL_STATE=(-0.098, -0.098),\n",
    "            VARIABLES_OF_INTEREST=(\"V\", \"W\"),\n",
    "        ),\n",
    "        coupling={\n",
    "            \"delayed\": DelayedLinearCoupling(\n",
    "                incoming_states=\"V\",\n",
    "                G=G,\n",
    "                buffer_strategy=buffer_strategy,\n",
    "            )\n",
    "        },\n",
    "        graph=graph,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_loss_fn(model_fn, state):\n",
    "    \"\"\"Create a loss function for gradient benchmarking.\"\"\"\n",
    "    def loss_fn(G_value):\n",
    "        state.coupling.delayed.G = G_value\n",
    "        result = model_fn(state)\n",
    "        return jnp.mean(result.ys[-50:, 0, :])\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "def run_benchmark(n_regions, dt, n_timesteps, n_forward_runs=3, n_gradient_runs=3):\n",
    "    \"\"\"Run benchmark for all strategies at a specific configuration.\"\"\"\n",
    "    # Create random graph\n",
    "    graph = DenseDelayGraph.random(n_regions, max_delay=MAX_DELAY, key=jax.random.key(0))\n",
    "\n",
    "    # Compute simulation parameters\n",
    "    simulation_length = n_timesteps * dt\n",
    "    max_delay = float(graph.delays.max())\n",
    "    t_offset = max_delay + dt\n",
    "    history_length = int(np.ceil(max_delay / dt)) + 1\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Prepare all models\n",
    "    models = {}\n",
    "    states = {}\n",
    "    for strategy in STRATEGIES:\n",
    "        network = create_network(graph, G, strategy)\n",
    "        model_fn, state = prepare(\n",
    "            network,\n",
    "            Heun(),\n",
    "            t0=0.0 + t_offset,\n",
    "            t1=simulation_length + t_offset,\n",
    "            dt=dt,\n",
    "        )\n",
    "        models[strategy] = jax.jit(model_fn)\n",
    "        states[strategy] = state\n",
    "\n",
    "    # Warm-up (JIT compilation)\n",
    "    sim_results = {}\n",
    "    for strategy in STRATEGIES:\n",
    "        result = models[strategy](states[strategy])\n",
    "        jax.block_until_ready(result.ys)\n",
    "        sim_results[strategy] = result\n",
    "\n",
    "    # Forward benchmark\n",
    "    forward_times = {s: [] for s in STRATEGIES}\n",
    "    for _ in range(n_forward_runs):\n",
    "        for strategy in STRATEGIES:\n",
    "            t_start = time.perf_counter()\n",
    "            result = models[strategy](states[strategy])\n",
    "            jax.block_until_ready(result.ys)\n",
    "            t_end = time.perf_counter()\n",
    "            forward_times[strategy].append(t_end - t_start)\n",
    "            sim_results[strategy] = result\n",
    "\n",
    "    # Gradient benchmark\n",
    "    grad_fns = {}\n",
    "    for strategy in STRATEGIES:\n",
    "        loss_fn = make_loss_fn(models[strategy], states[strategy])\n",
    "        grad_fns[strategy] = jax.jit(jax.value_and_grad(loss_fn))\n",
    "\n",
    "    # Warm-up gradients\n",
    "    G_init = jnp.array(G)\n",
    "    grad_results = {}\n",
    "    for strategy in STRATEGIES:\n",
    "        val, grad = grad_fns[strategy](G_init)\n",
    "        jax.block_until_ready(grad)\n",
    "        grad_results[strategy] = (val, grad)\n",
    "\n",
    "    # Gradient timing\n",
    "    gradient_times = {s: [] for s in STRATEGIES}\n",
    "    for _ in range(n_gradient_runs):\n",
    "        for strategy in STRATEGIES:\n",
    "            t_start = time.perf_counter()\n",
    "            val, grad = grad_fns[strategy](G_init)\n",
    "            jax.block_until_ready(grad)\n",
    "            t_end = time.perf_counter()\n",
    "            gradient_times[strategy].append(t_end - t_start)\n",
    "            grad_results[strategy] = (val, grad)\n",
    "\n",
    "    # Correctness verification (use roll as reference)\n",
    "    V_ref = np.array(sim_results[\"roll\"].ys[:, 0, :])\n",
    "    _, grad_ref = grad_results[\"roll\"]\n",
    "\n",
    "    for strategy in STRATEGIES:\n",
    "        V = np.array(sim_results[strategy].ys[:, 0, :])\n",
    "        _, grad = grad_results[strategy]\n",
    "\n",
    "        corr_V = np.corrcoef(V_ref.flatten(), V.flatten())[0, 1]\n",
    "        rmse_V = np.sqrt(np.mean((V_ref - V) ** 2))\n",
    "        max_err_V = np.max(np.abs(V_ref - V))\n",
    "        grad_diff = abs(float(grad_ref) - float(grad))\n",
    "\n",
    "        results[strategy] = {\n",
    "            \"forward_mean\": np.mean(forward_times[strategy]),\n",
    "            \"forward_std\": np.std(forward_times[strategy]),\n",
    "            \"gradient_mean\": np.mean(gradient_times[strategy]),\n",
    "            \"gradient_std\": np.std(gradient_times[strategy]),\n",
    "            \"correlation\": corr_V,\n",
    "            \"rmse\": rmse_V,\n",
    "            \"max_error\": max_err_V,\n",
    "            \"grad_diff\": grad_diff,\n",
    "            \"is_correct\": corr_V > 0.99,\n",
    "        }\n",
    "\n",
    "    results[\"_meta\"] = {\n",
    "        \"history_length\": history_length,\n",
    "        \"simulation_length\": simulation_length,\n",
    "        \"max_delay\": max_delay,\n",
    "    }\n",
    "\n",
    "    return results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Benchmark\n",
    "\n",
    "The benchmark sweeps over all combinations of network size and time step, measuring both forward simulation and gradient computation times."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "@cache(\"benchmark_sweep\", redo=False)\n",
    "def run_full_benchmark():\n",
    "    \"\"\"Run the complete benchmark sweep (cached).\"\"\"\n",
    "    all_results = {}\n",
    "    total_configs = len(DT_VALUES) * len(NETWORK_SIZES)\n",
    "    config_num = 0\n",
    "\n",
    "    for n_regions in NETWORK_SIZES:\n",
    "        all_results[n_regions] = {}\n",
    "        for dt in DT_VALUES:\n",
    "            config_num += 1\n",
    "            sim_length = FIXED_TIMESTEPS * dt\n",
    "            print(f\"[{config_num}/{total_configs}] N={n_regions}, dt={dt}, T={sim_length:.1f}ms\")\n",
    "\n",
    "            try:\n",
    "                result = run_benchmark(n_regions, dt, FIXED_TIMESTEPS, N_FORWARD_RUNS, N_GRADIENT_RUNS)\n",
    "                all_results[n_regions][dt] = result\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR: {e}\")\n",
    "                all_results[n_regions][dt] = None\n",
    "\n",
    "    return all_results\n",
    "\n",
    "all_results = run_full_benchmark()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Create matrices for best strategy indices\n",
    "strategy_list = STRATEGIES\n",
    "best_forward = np.zeros((len(NETWORK_SIZES), len(DT_VALUES)), dtype=int)\n",
    "best_gradient = np.zeros((len(NETWORK_SIZES), len(DT_VALUES)), dtype=int)\n",
    "forward_speedups = {s: np.zeros((len(NETWORK_SIZES), len(DT_VALUES))) for s in STRATEGIES}\n",
    "gradient_speedups = {s: np.zeros((len(NETWORK_SIZES), len(DT_VALUES))) for s in STRATEGIES}\n",
    "\n",
    "for i, n_regions in enumerate(NETWORK_SIZES):\n",
    "    for j, dt in enumerate(DT_VALUES):\n",
    "        if all_results[n_regions][dt] is not None:\n",
    "            result = all_results[n_regions][dt]\n",
    "\n",
    "            # Forward: find fastest\n",
    "            fwd_times = [result[s][\"forward_mean\"] for s in strategy_list]\n",
    "            best_forward[i, j] = np.argmin(fwd_times)\n",
    "            ref_fwd = result[\"roll\"][\"forward_mean\"]\n",
    "            for k, s in enumerate(strategy_list):\n",
    "                forward_speedups[s][i, j] = ref_fwd / result[s][\"forward_mean\"]\n",
    "\n",
    "            # Gradient: find fastest\n",
    "            grad_times = [result[s][\"gradient_mean\"] for s in strategy_list]\n",
    "            best_gradient[i, j] = np.argmin(grad_times)\n",
    "            ref_grad = result[\"roll\"][\"gradient_mean\"]\n",
    "            for k, s in enumerate(strategy_list):\n",
    "                gradient_speedups[s][i, j] = ref_grad / result[s][\"gradient_mean\"]\n",
    "        else:\n",
    "            best_forward[i, j] = -1\n",
    "            best_gradient[i, j] = -1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Strategy visualization settings\n",
    "colors = ['gold', 'steelblue', '#000000']\n",
    "STRATEGY_CONFIG = {\n",
    "    \"roll\": {\"color\": colors[0], \"marker\": \"s\"},\n",
    "    \"circular\": {\"color\": colors[1], \"marker\": \"o\"},\n",
    "    \"preallocated\": {\"color\": colors[2], \"marker\": \"^\"},\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
    "\n",
    "# Create custom colormap for strategies\n",
    "strategy_colors = [STRATEGY_CONFIG[s][\"color\"] for s in strategy_list]\n",
    "strategy_cmap = ListedColormap(strategy_colors)\n",
    "legend_elements = [Patch(facecolor=STRATEGY_CONFIG[s][\"color\"], label=s) for s in strategy_list]\n",
    "\n",
    "# ---- Row 1: Best Strategy Heatmaps ----\n",
    "\n",
    "# Plot 1: Best strategy for forward pass\n",
    "ax1 = axes[0, 0]\n",
    "im1 = ax1.imshow(best_forward, aspect=\"auto\", cmap=strategy_cmap, vmin=0, vmax=2)\n",
    "ax1.set_xticks(range(len(DT_VALUES)))\n",
    "ax1.set_xticklabels([str(dt) for dt in DT_VALUES], rotation=45, ha=\"right\")\n",
    "ax1.set_yticks(range(len(NETWORK_SIZES)))\n",
    "ax1.set_yticklabels([str(n) for n in NETWORK_SIZES])\n",
    "ax1.set_xlabel(\"dt (ms)\")\n",
    "ax1.set_ylabel(\"Network Size (N)\")\n",
    "ax1.set_title(\"Best Strategy: Forward Pass\")\n",
    "ax1.legend(handles=legend_elements, loc=\"upper right\", fontsize=7)\n",
    "\n",
    "# Plot 2: Best strategy for gradient\n",
    "ax2 = axes[0, 1]\n",
    "im2 = ax2.imshow(best_gradient, aspect=\"auto\", cmap=strategy_cmap, vmin=0, vmax=2)\n",
    "ax2.set_xticks(range(len(DT_VALUES)))\n",
    "ax2.set_xticklabels([str(dt) for dt in DT_VALUES], rotation=45, ha=\"right\")\n",
    "ax2.set_yticks(range(len(NETWORK_SIZES)))\n",
    "ax2.set_yticklabels([str(n) for n in NETWORK_SIZES])\n",
    "ax2.set_xlabel(\"dt (ms)\")\n",
    "ax2.set_ylabel(\"Network Size (N)\")\n",
    "ax2.set_title(\"Best Strategy: Gradient\")\n",
    "ax2.legend(handles=legend_elements, loc=\"upper right\", fontsize=7)\n",
    "\n",
    "# Plot 3: Summary line plot - speedup vs dt for largest network\n",
    "ax3 = axes[0, 2]\n",
    "n_largest = NETWORK_SIZES[-1]\n",
    "for strategy in strategy_list:\n",
    "    fwd_spd = []\n",
    "    grad_spd = []\n",
    "    dts = []\n",
    "    for j, dt in enumerate(DT_VALUES):\n",
    "        if all_results[n_largest][dt] is not None:\n",
    "            dts.append(dt)\n",
    "            fwd_spd.append(forward_speedups[strategy][-1, j])\n",
    "            grad_spd.append(gradient_speedups[strategy][-1, j])\n",
    "    ax3.plot(dts, fwd_spd, marker=STRATEGY_CONFIG[strategy][\"marker\"],\n",
    "             color=STRATEGY_CONFIG[strategy][\"color\"], label=f\"{strategy} (fwd)\",\n",
    "             lw=2, markersize=6, linestyle=\"-\")\n",
    "    ax3.plot(dts, grad_spd, marker=STRATEGY_CONFIG[strategy][\"marker\"],\n",
    "             color=STRATEGY_CONFIG[strategy][\"color\"], label=f\"{strategy} (grad)\",\n",
    "             lw=1.5, markersize=5, linestyle=\"--\", alpha=0.7)\n",
    "ax3.axhline(y=1.0, color=\"red\", linestyle=\":\", alpha=0.5)\n",
    "ax3.set_xscale(\"log\")\n",
    "ax3.set_xlabel(\"dt (ms)\")\n",
    "ax3.set_ylabel(\"Speedup vs roll\")\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.set_title(f\"Speedup vs dt (N={n_largest})\")\n",
    "ax3.legend(fontsize=6, ncol=2)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.invert_xaxis()\n",
    "\n",
    "# ---- Row 2: Gradient/Forward ratio for each strategy ----\n",
    "\n",
    "for idx, strategy in enumerate(strategy_list):\n",
    "    ax = axes[1, idx]\n",
    "\n",
    "    # Compute forward and gradient times matrices\n",
    "    forward_times = np.zeros((len(NETWORK_SIZES), len(DT_VALUES)))\n",
    "    gradient_times = np.zeros((len(NETWORK_SIZES), len(DT_VALUES)))\n",
    "\n",
    "    for i, n_regions in enumerate(NETWORK_SIZES):\n",
    "        for j, dt in enumerate(DT_VALUES):\n",
    "            if all_results[n_regions][dt] is not None:\n",
    "                forward_times[i, j] = all_results[n_regions][dt][strategy][\"forward_mean\"]\n",
    "                gradient_times[i, j] = all_results[n_regions][dt][strategy][\"gradient_mean\"]\n",
    "            else:\n",
    "                forward_times[i, j] = np.nan\n",
    "                gradient_times[i, j] = np.nan\n",
    "\n",
    "    # Show gradient/forward ratio\n",
    "    ratio = gradient_times / forward_times\n",
    "\n",
    "    im = ax.imshow(ratio, aspect=\"auto\", cmap=\"cividis_r\", vmin=1, vmax=20)\n",
    "    ax.set_xticks(range(len(DT_VALUES)))\n",
    "    ax.set_xticklabels([str(dt) for dt in DT_VALUES], rotation=45, ha=\"right\")\n",
    "    ax.set_yticks(range(len(NETWORK_SIZES)))\n",
    "    ax.set_yticklabels([str(n) for n in NETWORK_SIZES])\n",
    "    ax.set_xlabel(\"dt (ms)\")\n",
    "    ax.set_ylabel(\"Network Size (N)\")\n",
    "    ax.set_title(f\"{strategy}: Gradient/Forward Ratio\")\n",
    "    plt.colorbar(im, ax=ax, label=\"Ratio (grad/fwd)\")\n",
    "\n",
    "    # Add text annotations\n",
    "    for i in range(len(NETWORK_SIZES)):\n",
    "        for j in range(len(DT_VALUES)):\n",
    "            if not np.isnan(ratio[i, j]):\n",
    "                color = \"white\" if ratio[i, j] > 10 else \"black\"\n",
    "                ax.text(j, i, f\"{ratio[i, j]:.1f}\", ha=\"center\", va=\"center\",\n",
    "                        fontsize=6, color=color)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Buffer Strategy Benchmark: N x dt Sweep\\n\"\n",
    "    rf\"timesteps={FIXED_TIMESTEPS}, $\\tau_\\max=${MAX_DELAY}ms  , G={G}\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness Verification\n",
    "\n",
    "All strategies produce numerically equivalent results (correlation > 0.99 with roll reference):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "all_correct = True\n",
    "for n_regions in NETWORK_SIZES:\n",
    "    for dt in DT_VALUES:\n",
    "        if all_results[n_regions][dt] is not None:\n",
    "            result = all_results[n_regions][dt]\n",
    "            for strategy in STRATEGIES:\n",
    "                if not result[strategy][\"is_correct\"]:\n",
    "                    print(f\"FAIL: N={n_regions}, dt={dt}, {strategy}: corr={result[strategy]['correlation']:.8f}\")\n",
    "                    all_correct = False\n",
    "\n",
    "if all_correct:\n",
    "    print(\"All configurations PASSED correctness verification.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Count wins for each strategy\n",
    "forward_wins = {s: 0 for s in strategy_list}\n",
    "gradient_wins = {s: 0 for s in strategy_list}\n",
    "total_valid = 0\n",
    "\n",
    "for i, n_regions in enumerate(NETWORK_SIZES):\n",
    "    for j, dt in enumerate(DT_VALUES):\n",
    "        if all_results[n_regions][dt] is not None:\n",
    "            total_valid += 1\n",
    "            forward_wins[strategy_list[best_forward[i, j]]] += 1\n",
    "            gradient_wins[strategy_list[best_gradient[i, j]]] += 1\n",
    "\n",
    "print(f\"Total configurations tested: {total_valid}\")\n",
    "print(f\"\\nForward Pass Wins:\")\n",
    "for s in strategy_list:\n",
    "    pct = 100 * forward_wins[s] / total_valid if total_valid > 0 else 0\n",
    "    print(f\"  {s:<15}: {forward_wins[s]:>3} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nGradient Wins:\")\n",
    "for s in strategy_list:\n",
    "    pct = 100 * gradient_wins[s] / total_valid if total_valid > 0 else 0\n",
    "    print(f\"  {s:<15}: {gradient_wins[s]:>3} ({pct:.1f}%)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **No universal winner**: The best strategy depends on network size, time step, and whether gradients are needed.\n",
    "\n",
    "2. **Forward vs Gradient trade-offs**: Strategies that perform well for forward simulation may not be optimal for gradient computation due to different memory access patterns in reverse-mode autodiff.\n",
    "\n",
    "3. **Buffer size matters**: Smaller dt creates larger buffers, which changes the relative performance of strategies.\n",
    "\n",
    "4. **Hardware matters**: These results are for CPU. GPU execution can yield different results due to higher memory bandwidth and different memory access characteristics.\n",
    "\n",
    "5. **Practical guidance**:\n",
    "   - For **forward-only** simulation: circular or preallocated often win\n",
    "   - For **gradient-based optimization**: test your specific configuration, as the optimal choice varies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)",
   "path": "/home/marius/Documents/Projekte/tvboptim/.venv/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}