{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Subspace coupling enables **hierarchical network interactions** where fine-grained nodes are organized into coarser regions. This pattern is fundamental in brain network modeling for cortical surface simulations, where thousands of vertices belong to anatomical parcels that communicate via long-range white matter tracts.\n",
    "\n",
    "The key idea: instead of coupling all nodes directly, we **aggregate node states to regions, apply coupling at the regional level, then distribute results back to nodes**. This three-stage pattern is implemented through the standard coupling API: `prepare()`, `compute()`, and `update_state()`.\n",
    "\n",
    "## Use Case: Surface Simulations\n",
    "\n",
    "In The Virtual Brain (TVB), surface simulations model cortical activity at the vertex level (10 thousands of vertices) while maintaining regional connectivity via structural connectomes (hundreds of regions). This creates a two-level hierarchy:\n",
    "\n",
    "- **Node level**: Fine-grained cortical vertices with local connectivity\n",
    "- **Regional level**: Coarse anatomical parcels with long-range delayed connectivity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install dependencies if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab - installing dependencies...\")\n",
    "    !pip install -q tvboptim\n",
    "    print(\"✓ Dependencies installed!\")\n",
    "except ImportError:\n",
    "    pass  # Not in Colab, assume dependencies are available"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "import time\n",
    "from tvboptim.experimental.network_dynamics import Network, solve\n",
    "from tvboptim.experimental.network_dynamics.dynamics.tvb import ReducedWongWang\n",
    "from tvboptim.experimental.network_dynamics.coupling.linear import FastLinearCoupling, DelayedLinearCoupling\n",
    "from tvboptim.experimental.network_dynamics.coupling.subspace import SubspaceCoupling\n",
    "from tvboptim.experimental.network_dynamics.graph import SparseGraph, DenseDelayGraph\n",
    "from tvboptim.experimental.network_dynamics.solvers import Euler"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Subspace Coupling Pattern\n",
    "\n",
    "## Conceptual Overview\n",
    "\n",
    "Subspace coupling operates in three stages:\n",
    "\n",
    "```\n",
    "1. AGGREGATE:  [n_states, n_nodes] → [n_states, n_regions]\n",
    "2. COUPLE:     Apply coupling at regional level\n",
    "3. DISTRIBUTE: [n_coupling, n_regions] → [n_coupling, n_nodes]\n",
    "```\n",
    "\n",
    "**Stage 1 (Aggregate)**: Average node states within each region\n",
    "$$\n",
    "s_r = \\frac{1}{|R_r|} \\sum_{i \\in R_r} s_i\n",
    "$$\n",
    "\n",
    "**Stage 2 (Couple)**: Apply inner coupling on regional graph\n",
    "$$\n",
    "c_r = \\sum_{r'} w_{rr'} f(s_{r'}(t - \\tau_{rr'}))\n",
    "$$\n",
    "\n",
    "**Stage 3 (Distribute)**: Broadcast regional coupling to constituent nodes\n",
    "$$\n",
    "c_i = c_{\\text{region}(i)}\n",
    "$$\n",
    "\n",
    "## Implementation: The Coupling API\n",
    "\n",
    "Let's see how this pattern maps to the three-phase coupling API. We'll show conceptual code snippets that capture the essence of `SubspaceCoupling`.\n",
    "\n",
    "### Phase 1: `prepare()` - Precompute Regional Structures\n",
    "\n",
    "```python\n",
    "def prepare(self, network, dt, t0, t1):\n",
    "    \"\"\"Precompute aggregation matrices and prepare inner coupling.\"\"\"\n",
    "\n",
    "    # Build normalized aggregation matrix [n_nodes, n_regions]\n",
    "    # Each node contributes 1/|region| to its region's mean\n",
    "    region_one_hot = jnp.eye(self.n_regions)[self.region_mapping]\n",
    "    region_counts = jnp.sum(region_one_hot, axis=0)\n",
    "    region_one_hot_normalized = region_one_hot / region_counts[None, :]\n",
    "\n",
    "    # Create regional network context for inner coupling\n",
    "    # This provides a Network-like interface for the regional graph\n",
    "    regional_context = self._create_regional_context(network, ...)\n",
    "\n",
    "    # Prepare inner coupling (e.g., DelayedLinearCoupling on regional graph)\n",
    "    inner_data, inner_state = self.inner_coupling.prepare(\n",
    "        regional_context, dt, t0, t1\n",
    "    )\n",
    "\n",
    "    # Compute initial aggregated state for caching\n",
    "    initial_regional_state = self.aggregate(\n",
    "        network.initial_state, region_one_hot_normalized\n",
    "    )\n",
    "\n",
    "    return coupling_data, coupling_state\n",
    "```\n",
    "\n",
    "**Key insight**: We precompute the aggregation matrix once, avoiding repeated computation. For sparse mappings (many nodes, few regions), we use sparse matrices.\n",
    "\n",
    "### Phase 2: `compute()` - Three-Stage Computation\n",
    "\n",
    "```python\n",
    "def compute(self, t, state, coupling_data, coupling_state, params, graph):\n",
    "    \"\"\"Aggregate → couple → distribute.\"\"\"\n",
    "\n",
    "    # Stage 1: Use cached aggregated regional state\n",
    "    # (computed in previous update_state, avoids redundant aggregation)\n",
    "    regional_state = coupling_state.cached_regional_state\n",
    "    # Shape: [n_states, n_regions]\n",
    "\n",
    "    # Stage 2: Compute coupling at regional level\n",
    "    regional_coupling = self.inner_coupling.compute(\n",
    "        t,\n",
    "        regional_state,\n",
    "        coupling_data.inner_data,\n",
    "        coupling_state.inner_state,\n",
    "        self.inner_coupling.params,\n",
    "        self.regional_graph  # Regional connectivity\n",
    "    )\n",
    "    # Shape: [n_coupling_inputs, n_regions]\n",
    "\n",
    "    # Stage 3: Distribute regional coupling to nodes (broadcast)\n",
    "    node_coupling = self.distribute(\n",
    "        regional_coupling, coupling_data.region_mapping\n",
    "    )\n",
    "    # Shape: [n_coupling_inputs, n_nodes]\n",
    "\n",
    "    return node_coupling\n",
    "```\n",
    "\n",
    "**Performance optimization**: We cache the aggregated state from the previous timestep, avoiding redundant aggregation in `compute()`.\n",
    "\n",
    "### Phase 3: `update_state()` - Update and Cache\n",
    "\n",
    "```python\n",
    "def update_state(self, coupling_data, coupling_state, new_state):\n",
    "    \"\"\"Update inner coupling state and cache new aggregated state.\"\"\"\n",
    "\n",
    "    # Aggregate new node state to regional state\n",
    "    regional_state = self.aggregate(\n",
    "        new_state, coupling_data.region_one_hot_normalized\n",
    "    )\n",
    "\n",
    "    # Update inner coupling (e.g., delay buffer with regional states)\n",
    "    new_inner_state = self.inner_coupling.update_state(\n",
    "        coupling_data.inner_data,\n",
    "        coupling_state.inner_state,\n",
    "        regional_state  # Regional state for delay buffer\n",
    "    )\n",
    "\n",
    "    # Cache aggregated state for next compute()\n",
    "    return Bunch(\n",
    "        inner_state=new_inner_state,\n",
    "        cached_regional_state=regional_state\n",
    "    )\n",
    "```\n",
    "\n",
    "**Temporal optimization**: The aggregated state computed here is reused in the next `compute()` call, eliminating duplicate aggregation operations.\n",
    "\n",
    "## Aggregate and Distribute Methods\n",
    "\n",
    "These customizable methods implement the projection between node and regional spaces:\n",
    "\n",
    "```python\n",
    "def aggregate(self, node_state, coupling_data):\n",
    "    \"\"\"Aggregate node states to regional states (default: mean).\"\"\"\n",
    "    # node_state: [n_states, n_nodes]\n",
    "    # region_one_hot_normalized: [n_nodes, n_regions]\n",
    "\n",
    "    regional_state = node_state @ coupling_data.region_one_hot_normalized\n",
    "    # Shape: [n_states, n_regions]\n",
    "\n",
    "    return regional_state\n",
    "\n",
    "def distribute(self, regional_coupling, coupling_data):\n",
    "    \"\"\"Distribute regional coupling to nodes (default: broadcast).\"\"\"\n",
    "    # regional_coupling: [n_coupling_inputs, n_regions]\n",
    "    # region_mapping: [n_nodes] with region IDs\n",
    "\n",
    "    node_coupling = regional_coupling[:, coupling_data.region_mapping]\n",
    "    # Shape: [n_coupling_inputs, n_nodes]\n",
    "\n",
    "    return node_coupling\n",
    "```\n",
    "\n",
    "**Customization**: Override these methods for alternative strategies (weighted aggregation, scaled distribution, etc.).\n",
    "\n",
    "# Practical Example: Mixed Coupling\n",
    "\n",
    "Let's create a realistically sized surface simulation with both local and regional coupling:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Network dimensions\n",
    "n_nodes = 16000  # Cortical vertices\n",
    "n_regions = 76   # Brain regions\n",
    "t0, t1, dt = 0.0, 1000.0, 1.0\n",
    "\n",
    "# Regional connectivity: Structural connectome with delays\n",
    "region_mapping = jax.random.randint(\n",
    "    jax.random.key(42), (n_nodes,), 0, n_regions\n",
    ")\n",
    "\n",
    "regional_graph = DenseDelayGraph.random(\n",
    "    n_nodes=n_regions,\n",
    "    sparsity=0.8,      # 80% of connections present\n",
    "    max_delay=50.0,    # ~150mm at 3 m/s\n",
    "    key=jax.random.key(0)\n",
    ")\n",
    "\n",
    "# Local connectivity: Sparse short-range connections\n",
    "node_graph = SparseGraph.random(\n",
    "    n_nodes=n_nodes,\n",
    "    sparsity=0.000366,  # 0.0366% connectivity (typical density, depending on kernel)\n",
    "    key=jax.random.key(1)\n",
    ")\n",
    "\n",
    "print(f\"Local graph: {node_graph.nnz:,} edges (sparse)\")\n",
    "print(f\"Regional graph: {n_regions}×{n_regions} (dense with delays)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction\n",
    "\n",
    "Now create a network with two coupling types:\n",
    "\n",
    "1. **Instantaneous local coupling**: Fast connections between nearby vertices\n",
    "2. **Delayed regional coupling**: Long-range connections between brain regions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Local instantaneous coupling\n",
    "coupling_instant = FastLinearCoupling(local_states='S', G=0.2)\n",
    "\n",
    "# Regional delayed coupling via subspace\n",
    "coupling_delayed = SubspaceCoupling(\n",
    "    inner_coupling=DelayedLinearCoupling(incoming_states='S', G=0.05),\n",
    "    region_mapping=region_mapping,\n",
    "    regional_graph=regional_graph,\n",
    ")\n",
    "\n",
    "# Multi-coupling network\n",
    "network = Network(\n",
    "    dynamics=ReducedWongWang(I_o = 0.1),\n",
    "    coupling={\n",
    "        'instant': coupling_instant,   # Local vertices\n",
    "        'delayed': coupling_delayed    # Regional subspace\n",
    "    },\n",
    "    graph=node_graph\n",
    ")\n",
    "\n",
    "print(network)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key point**: The dynamics model (`ReducedWongWang`) declares two coupling inputs (`instant` and `delayed`). The network provides both through named couplings operating at different spatial scales.\n",
    "\n",
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "result = solve(network, Euler(), t0=t0, t1=t1, dt=dt)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nSimulation: {elapsed:.2f} seconds\")\n",
    "print(f\"Result shape: {result.ys.shape}\")\n",
    "print(f\"Time points: [{result.ts[0]:.1f}, {result.ts[-1]:.1f}] ms\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Inspection\n",
    "\n",
    "The network printer reveals the hierarchical structure:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tvboptim.experimental.network_dynamics.utils.printer import print_network\n",
    "\n",
    "print_network(network)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**:\n",
    "- Coupling 1 (`instant`): Operates on node graph (16,000 nodes, sparse)\n",
    "- Coupling 2 (`delayed`): Shows regional structure (76 regions, aggregation/distribution)\n",
    "- Max delay: ~50 ms for long-range regional connections\n",
    "\n",
    "# History Management for Regional Coupling\n",
    "\n",
    "When delayed regional coupling is used, the system needs history buffers at the regional level. The `_RegionalNetworkContext` handles this by aggregating node-level history to regional history.\n",
    "\n",
    "## Continuing Simulations\n",
    "\n",
    "If you set custom history on the network (e.g., continuing from a previous simulation), the regional coupling automatically aggregates it:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run initial simulation\n",
    "sim1 = solve(network, Euler(), t0=0.0, t1=500.0, dt=1.0)\n",
    "\n",
    "# Set as history and continue\n",
    "network.update_history(sim1)\n",
    "sim2 = solve(network, Euler(), t0=500.0, t1=1000.0, dt=1.0)\n",
    "\n",
    "print(f\"First simulation:  {sim1.ys.shape}\")\n",
    "print(f\"Second simulation: {sim2.ys.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regional coupling's `get_history()` method aggregates the node-level history to create appropriate regional delay buffers. This happens transparently via the shared history extraction utility.\n",
    "\n",
    "## Visualize Continued Simulation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 4.5), dpi = 200)\n",
    "\n",
    "# Sample 100 vertices\n",
    "sample_indices = jnp.linspace(0, n_nodes-1, 100, dtype=int)\n",
    "\n",
    "# Vertex time series: sim1 and sim2\n",
    "axes[0].plot(sim1.ts, sim1.ys[:, 0, sample_indices],\n",
    "             alpha=0.3, linewidth=0.5, color='steelblue', label='Sim 1')\n",
    "axes[0].plot(sim2.ts, sim2.ys[:, 0, sample_indices],\n",
    "             alpha=0.3, linewidth=0.5, color='coral', label='Sim 2')\n",
    "axes[0].axvline(500, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0].set_ylabel('S (synaptic gating)')\n",
    "axes[0].set_title(f'Cortical Activity: {len(sample_indices)} Vertices (Continued Simulation)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add zoom inset for vertices\n",
    "axins0 = inset_axes(axes[0], width=\"30%\", height=\"50%\", loc='lower left',\n",
    "                    bbox_to_anchor=(0.55, 0.1, 1, 1), bbox_transform=axes[0].transAxes)\n",
    "axins0.plot(sim1.ts, sim1.ys[:, 0, sample_indices[:]],\n",
    "            alpha=0.8, linewidth=1, color='steelblue')\n",
    "axins0.plot(sim2.ts, sim2.ys[:, 0, sample_indices[:]],\n",
    "            alpha=0.8, linewidth=1, color='coral')\n",
    "axins0.axvline(500, color='black', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "axins0.set_xlim(480, 520)\n",
    "axins0.set_ylim(sim1.ys[480:520, 0, sample_indices[:]].min() - 0.01,\n",
    "                sim1.ys[480:520, 0, sample_indices[:]].max() + 0.01)\n",
    "axins0.grid(True, alpha=0.3, linewidth=0.5)\n",
    "axins0.tick_params(labelsize=7)\n",
    "mark_inset(axes[0], axins0, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Mean regional activity\n",
    "regional_activity_sim1 = []\n",
    "regional_activity_sim2 = []\n",
    "for r in range(n_regions):\n",
    "    mask = region_mapping == r\n",
    "    regional_activity_sim1.append(jnp.mean(sim1.ys[:, 0, mask], axis=1))\n",
    "    regional_activity_sim2.append(jnp.mean(sim2.ys[:, 0, mask], axis=1))\n",
    "\n",
    "regional_activity_sim1 = jnp.array(regional_activity_sim1).T  # [time, n_regions]\n",
    "regional_activity_sim2 = jnp.array(regional_activity_sim2).T\n",
    "\n",
    "# Plot first 10 regions\n",
    "axes[1].plot(sim1.ts, regional_activity_sim1[:, :10],\n",
    "             alpha=0.7, linewidth=1.5, color='steelblue')\n",
    "axes[1].plot(sim2.ts, regional_activity_sim2[:, :10],\n",
    "             alpha=0.7, linewidth=1.5, color='coral')\n",
    "axes[1].axvline(500, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].set_xlabel('Time [ms]')\n",
    "axes[1].set_ylabel('Mean S per region')\n",
    "axes[1].set_title('Regional Activity: 10 Brain Regions (Continued Simulation)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add zoom inset for regional activity\n",
    "axins1 = inset_axes(axes[1], width=\"30%\", height=\"50%\", loc='lower left',\n",
    "                    bbox_to_anchor=(0.55, 0.1, 1, 1), bbox_transform=axes[1].transAxes)\n",
    "axins1.plot(sim1.ts, regional_activity_sim1[:, :10],\n",
    "            alpha=0.8, linewidth=1.5, color='steelblue')\n",
    "axins1.plot(sim2.ts, regional_activity_sim2[:, :10],\n",
    "            alpha=0.8, linewidth=1.5, color='coral')\n",
    "axins1.axvline(500, color='black', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "axins1.set_xlim(480, 520)\n",
    "axins1.set_ylim(regional_activity_sim1[480:520, 0:10].min() - 0.005,\n",
    "                regional_activity_sim1[480:520, 0:10].max() + 0.005)\n",
    "axins1.grid(True, alpha=0.3, linewidth=0.5)\n",
    "axins1.tick_params(labelsize=7)\n",
    "mark_inset(axes[1], axins1, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Implementation Insights\n",
    "\n",
    "## 1. Hierarchical State Management\n",
    "\n",
    "The coupling maintains two state representations:\n",
    "- **Node states**: `[n_states, n_nodes]` - full cortical surface\n",
    "- **Regional states**: `[n_states, n_regions]` - aggregated parcels\n",
    "\n",
    "Aggregation happens via matrix multiplication with precomputed sparse/dense matrices.\n",
    "\n",
    "## 2. Performance Optimizations\n",
    "\n",
    "**Temporal caching**: Avoid redundant aggregation by caching the aggregated state from `update_state()` for use in next `compute()`.\n",
    "\n",
    "**Spatial caching**: Precompute aggregation matrices in `prepare()` rather than rebuilding each timestep.\n",
    "\n",
    "**Sparse operations**: Use BCOO sparse format when `n_nodes >> n_regions` (enabled by default).\n",
    "\n",
    "## 3. Nested Coupling Architecture\n",
    "\n",
    "`SubspaceCoupling` wraps any inner coupling (instantaneous or delayed). The inner coupling sees only the regional graph, unaware it's part of a hierarchical system. This composition enables:\n",
    "\n",
    "- Local + regional coupling combinations\n",
    "- Delayed regional coupling with instantaneous local coupling\n",
    "- Multiple regional couplings with different parameters\n",
    "\n",
    "## 4. Network Context Pattern\n",
    "\n",
    "The `_RegionalNetworkContext` provides a minimal Network-like interface for the inner coupling's `prepare()` method. It implements:\n",
    "- `graph`: Regional graph\n",
    "- `dynamics`: For state name resolution\n",
    "- `get_history()`: Aggregates node history to regional history\n",
    "\n",
    "This duck-typing pattern avoids creating full Network objects while maintaining API compatibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)",
   "path": "/home/marius/Documents/Projekte/tvboptim/.venv/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}